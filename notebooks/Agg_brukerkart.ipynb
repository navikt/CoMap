{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "print(nx.__version__)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "\n",
    "\n",
    "from comap.mapper import CoMap\n",
    "from comap.graph_utils import (compute_graph_deltas)\n",
    "from comap.helper_utils import (get_reduced_categories)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list excel filer i mappe\n",
    "\n",
    "files = glob.glob('../../../Analyse/[A-Z,a-z]*.xlsx')\n",
    "\n",
    "print(\"** Listing files in directory: **\", files)\n",
    "\n",
    "input_excel = files[2]\n",
    "print(\"---> Reading (user):\", input_excel)\n",
    "\n",
    "# Read excel file into dataframe\n",
    "#sheetlist_usr = pd.read_excel(input_excel)\n",
    "#pd.read_excel(sheetname='Friteskt') #Hente en bestemt sheet\n",
    "#sheetlist_usr = list(np.unique(sheetlist_usr['Kandidatnummer'].dropna())) \n",
    "\n",
    "#cat_sheet = 'Kategorier' # navn på sheet som holder på kategoriene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recategorise and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recategorise\n",
    "#display(Markdown(\"**Aggregating user maps**\\n\"))\n",
    "drop_list_usr=[38,\n",
    "               43,\n",
    "               44,45,46,47,48,49]\n",
    "cat_dict_usr,cat_list_usr = get_reduced_categories(input_excel,'Kategorier',exclude=drop_list_usr)\n",
    "\n",
    "print(cat_dict_usr)\n",
    "\n",
    "#usrG, deltas_usr = build_aggregate_graph(file_usr, drop_nodes=drop_list_usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(df, node_list=[]):\n",
    "    \n",
    "    df_raw = df.copy()\n",
    "    \n",
    "    # tags: education, innsatsgruppe, age group\n",
    "    tag_list = df_raw.columns.values\n",
    "    \n",
    "    # extract mapping of node names to categories and put this in a list\n",
    "    category_list = df_raw.iloc[0].values\n",
    "    df_raw.drop( 0, inplace=True )\n",
    "\n",
    "    # extract raw node value from map and put in a list\n",
    "    raw_node_list = df_raw.iloc[1].values\n",
    "    df_raw.drop( 1, inplace=True )\n",
    "\n",
    "    # rename first column of dataframe to take name \"index\". This column contains original node names.\n",
    "    df_raw.rename(columns={tag_list[0] : 'index'},inplace = True)\n",
    "\n",
    "    for i in range(1,len(category_list)):\n",
    "        df_raw.rename(columns={tag_list[i] : category_list[i]},inplace=True)\n",
    "\n",
    "    # remove first column named 'index' containing node names (dataframe still has a \"normal\" index column)\n",
    "    del df_raw['index']\n",
    "    \n",
    "    # get array of column names\n",
    "    raw_index_list = df_raw.columns.values\n",
    "\n",
    "    # replace index by new cateogories --> should give a \"symmetric\" matrix\n",
    "    df_raw.set_index(raw_index_list,inplace=True) \n",
    "    \n",
    "    # remove \"comment node\"\n",
    "    #com = 101\n",
    "    #if(com in df_raw.columns):\n",
    "    #    df_raw.drop(columns=[101], inplace=True)\n",
    "    #    df_raw.drop(101, inplace=True)\n",
    "    #print(raw_index_list)\n",
    "    \n",
    "    # remove nodes not in include list\n",
    "    drop_nodes=[ c for c in df_raw.columns if c not in node_list ]\n",
    "    print('len dropnodes:', len(drop_nodes))\n",
    "    #print(len(df_raw))\n",
    "    #print(\"--->DROPPING NODES:\", drop_nodes)\n",
    "    if 43 in drop_nodes: \n",
    "        print(\"*********************************43 in DROPNODES\", drop_nodes)\n",
    "    print(df_raw.shape)\n",
    "    df_raw = df_raw.drop(columns=drop_nodes,axis=1)\n",
    "    df_raw = df_raw.drop(index=drop_nodes,axis=0)\n",
    "    print(df_raw.shape)\n",
    "    #print(len(df_raw))\n",
    "\n",
    "\n",
    "    # replace NaNs with zeros --> should now have a matrix with 0s and 1s\n",
    "    df_raw.fillna(0,inplace=True)\n",
    "\n",
    "    # collapse and add up nodes belonging to the same category. Corresponding cell values will be added. You are left with a reduced matrix.\n",
    "    # first collapse rows\n",
    "    \n",
    "    df_reduc = df_raw.groupby(df_raw.index).agg('sum')\n",
    "    # now collapse columns\n",
    "    df_reduc = df_reduc.T\n",
    "    df_reduc = df_reduc.groupby(df_raw.index).agg('sum')\n",
    "    #A_reduc = np.array(df_reduc.values)\n",
    "\n",
    "    #g = nx.from_pandas_adjacency(df_reduc)\n",
    "    df_raw2 = df_raw.copy()\n",
    "    new_index_list = list( range( len(df_raw.columns.values) ) )\n",
    "    #print(df_raw2.shape, len(new_index_list))\n",
    "    df_raw2.index = new_index_list #df_raw.set_index(new_index_list,inplace=False)\n",
    "    df_raw2.columns = new_index_list\n",
    "\n",
    "    return df_raw2, df_reduc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of individual map IDs present in input file\n",
    "sheetlist = list( np.unique( pd.read_excel( input_excel )['Kandidatnummer'].dropna() ) )\n",
    "num_maps = len(sheetlist)\n",
    "\n",
    "# initialise empty list of DiGraphs\n",
    "maps = {}\n",
    "# list to hold unconnected graphs (should be empty!)\n",
    "disconnects = []\n",
    "\n",
    "# loop over sheets in excel file, create networkx graph from sheet and add to maps\n",
    "for counter, sheet in enumerate(sheetlist):\n",
    "    \n",
    "    # get dataframe with user map\n",
    "    df_map_raw = pd.read_excel(input_excel, sheet_name=sheet)\n",
    "    print(\"Map #\", counter,\":\",len(df_map_raw))\n",
    "\n",
    "    # clean up to produce a symmetric adjacency matrix\n",
    "    df_map_clean_raw, df_map_clean_red = clean_up(df_map_raw, node_list=cat_dict_usr)\n",
    "    print(\"raw shape:\", df_map_clean_raw.shape,\"reduced shape:\", df_map_clean_red.shape)\n",
    "    \n",
    "    # create DiGraphs of both raw and recategorised graphs and append to list\n",
    "    g_raw   = nx.from_pandas_adjacency(df_map_clean_raw, create_using=nx.DiGraph)\n",
    "    g_recat = nx.from_pandas_adjacency(df_map_clean_red, create_using=nx.DiGraph)\n",
    "    \n",
    "    # check that all nodes are accounted for\n",
    "    if( ( len(df_map_clean_raw) != len(g_raw) ) ):\n",
    "        print(\"Mismatch in raw:\",counter, len(df_map_clean_raw), len(g_raw))\n",
    "    if( ( len(df_map_clean_red) != len(g_recat) ) ):\n",
    "        print(\"Mismatch in recat:\",counter, len(df_map_clean_red), len(g_recat))\n",
    "    \n",
    "    # check that both raw and reduced graphs are connected\n",
    "    if( ( nx.is_connected( g_raw.to_undirected() ) ) == False \n",
    "       or ( nx.is_connected( g_recat.to_undirected() ) )== False ):\n",
    "       print(\"Connected? \", nx.is_connected(g_raw.to_undirected()), nx.is_connected(g_recat.to_undirected()) )\n",
    "       largest_cc_raw = len(max(nx.connected_component_subgraphs(g_raw.to_undirected()), key=len))\n",
    "       largest_cc_recat = len(max(nx.connected_component_subgraphs(g_recat.to_undirected()), key=len))\n",
    "       smallest_cc_recat = min(nx.connected_component_subgraphs(g_recat.to_undirected()), key=len)\n",
    "       print(\"Largest raw: \", len(g_raw), largest_cc_raw )\n",
    "       print(\"Larget recat:\", len(g_recat), largest_cc_recat )\n",
    "       print(\"Smallest recat:\", smallest_cc_recat.nodes())\n",
    "       \n",
    "       if(nx.is_connected(g_recat.to_undirected())==False):\n",
    "           Gc = min(nx.connected_component_subgraphs(g_recat.to_undirected()), key=len)\n",
    "           print(\"Connected components:\", Gc.nodes())\n",
    "           disconnects.append( list(Gc.nodes())[0] )\n",
    "    \n",
    "    # Add networkx graphs to dictionary\n",
    "    maps[g_raw] = g_recat\n",
    "    \n",
    "\n",
    "print(\"Number of maps:\", len(maps))\n",
    "print(\"disconnects:\", disconnects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict_usr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bruker = CoMap(name='Agg_bruker')\n",
    "deltas = compute_graph_deltas( maps )\n",
    "G_bruker.aggregate_maps(maps.values(), cat_dict_usr)\n",
    "G_bruker.set_deltas(deltas)\n",
    "nx.draw_circular(G_bruker.map, node_color=G_bruker.node_colors.values(), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bruker.plot_map_deltas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bruker.plot_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bruker.map_properties(sort_by=['Pagerank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bruker.plot_quadrant_scatter()\n",
    "#plt.savefig('non-synthetic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, m_diff, arr = G_bruker.generate_synthetic_graph(noise_scale=.5, smear_func='laplace')\n",
    "#nx.draw_circular(S.map, node_color=S.node_colors.values(), with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smear_func='sl'\n",
    "func = smear_func in ['laplace','normal']\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.plot_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.get_n_highest_ranking_nodes(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.plot_quadrant_scatter()\n",
    "#plt.savefig('synthetic.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
